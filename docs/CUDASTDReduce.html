<!-- HTML header for doxygen 1.8.13-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Taskflow Handbook</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="icon" type="image/x-icon" href="favicon.ico" />
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="taskflow_logo.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname"><a href="https://taskflow.github.io/">Taskflow</a>
   &#160;<span id="projectnumber">3.2.0-Master-Branch</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('CUDASTDReduce.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Parallel Reduction</div></div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#CUDASTDParallelReductionIncludeTheHeader">Include the Header</a></li>
<li class="level1"><a href="#CUDASTDReduceItemsWithAnInitialValue">Reduce a Range of Items with an Initial Value</a></li>
<li class="level1"><a href="#CUDASTDReduceItemsWithoutAnInitialValue">Reduce a Range of Items without an Initial Value</a></li>
<li class="level1"><a href="#CUDASTDReduceTransformedItemsWithAnInitialValue">Reduce a Range of Transformed Items with an Initial Value</a></li>
<li class="level1"><a href="#CUDASTDReduceTransformedItemsWithoutAnInitialValue">Reduce a Range of Transformed Items without an Initial Value</a></li>
</ul>
</div>
<div class="textblock"><p>Taskflow provides standard template methods for reducing a range of items on a CUDA GPU.</p>
<h1><a class="anchor" id="CUDASTDParallelReductionIncludeTheHeader"></a>
Include the Header</h1>
<p>You need to include the header file, <code>taskflow/cuda/algorithm/reduce.hpp</code>, for using the parallel-reduction algorithm.</p>
<h1><a class="anchor" id="CUDASTDReduceItemsWithAnInitialValue"></a>
Reduce a Range of Items with an Initial Value</h1>
<p><a class="el" href="namespacetf.html#a8a872d2a0ac73a676713cb5be5aa688c" title="performs asynchronous parallel reduction over a range of items">tf::cuda_reduce</a> performs a parallel reduction over a range of elements specified by <code>[first, last)</code> using the binary operator <code>bop</code> and stores the reduced result in <code>result</code>. It represents the parallel execution of the following reduction loop on a GPU:</p>
<div class="fragment"><div class="line"><span class="keywordflow">while</span> (first != last) {</div>
<div class="line">  *result = bop(*result, *first++);</div>
<div class="line">}</div>
</div><!-- fragment --><p>The variable <code>result</code> participates in the reduction loop and must be initialized with an initial value. The following code performs a parallel reduction to sum all the numbers in the given range with an initial value <code>1000</code>:</p>
<div class="fragment"><div class="line"><span class="keyword">const</span> <span class="keywordtype">size_t</span> N = 1000000;</div>
<div class="line"><span class="keywordtype">int</span>* res = tf::cuda_malloc_shared&lt;int&gt;(1);  <span class="comment">// result</span></div>
<div class="line"><span class="keywordtype">int</span>* vec = tf::cuda_malloc_shared&lt;int&gt;(N);  <span class="comment">// vector</span></div>
<div class="line"> </div>
<div class="line"><span class="comment">// initializes the data</span></div>
<div class="line">*res = 1000;</div>
<div class="line"><span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> i=0; i&lt;N; i++) </div>
<div class="line">  vec[i] = i;</div>
<div class="line">} </div>
<div class="line"> </div>
<div class="line"><span class="comment">// queries the required buffer size to reduce N elements using the given policy</span></div>
<div class="line"><a class="code hl_class" href="classtf_1_1cudaExecutionPolicy.html">tf::cudaDefaultExecutionPolicy</a> policy;</div>
<div class="line"><span class="keyword">auto</span> bytes  = tf::cuda_reduce_buffer_size&lt;tf::cudaDefaultExecutionPolicy, int&gt;(N);</div>
<div class="line"><span class="keyword">auto</span> buffer = tf::cuda_malloc_device&lt;std::byte&gt;(bytes);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// *res = 1000 + (0 + 1 + 2 + 3 + 4 + ... + N-1)</span></div>
<div class="line"><a class="code hl_function" href="namespacetf.html#a8a872d2a0ac73a676713cb5be5aa688c">tf::cuda_reduce</a>(policy,</div>
<div class="line">  vec, vec + N, res, [] __device__ (<span class="keywordtype">int</span> a, <span class="keywordtype">int</span> b) { <span class="keywordflow">return</span> a + b; }, buffer</div>
<div class="line">);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// synchronize the execution</span></div>
<div class="line">policy.synchronize();</div>
<div class="line"> </div>
<div class="line"><span class="comment">// delete the memory</span></div>
<div class="line"><a class="code hl_function" href="namespacetf.html#ac7a8fe7456b888d6072ba94783c5003c">tf::cuda_free</a>(buffer);</div>
<div class="line"><a class="code hl_function" href="namespacetf.html#ac7a8fe7456b888d6072ba94783c5003c">tf::cuda_free</a>(res);</div>
<div class="line"><a class="code hl_function" href="namespacetf.html#ac7a8fe7456b888d6072ba94783c5003c">tf::cuda_free</a>(vec);</div>
<div class="ttc" id="aclasstf_1_1cudaExecutionPolicy_html"><div class="ttname"><a href="classtf_1_1cudaExecutionPolicy.html">tf::cudaExecutionPolicy</a></div><div class="ttdoc">class to define execution policy for CUDA standard algorithms</div><div class="ttdef"><b>Definition</b> cuda_execution_policy.hpp:29</div></div>
<div class="ttc" id="anamespacetf_html_a8a872d2a0ac73a676713cb5be5aa688c"><div class="ttname"><a href="namespacetf.html#a8a872d2a0ac73a676713cb5be5aa688c">tf::cuda_reduce</a></div><div class="ttdeci">void cuda_reduce(P &amp;&amp;p, I first, I last, T *res, O op, void *buf)</div><div class="ttdoc">performs asynchronous parallel reduction over a range of items</div><div class="ttdef"><b>Definition</b> reduce.hpp:212</div></div>
<div class="ttc" id="anamespacetf_html_ac7a8fe7456b888d6072ba94783c5003c"><div class="ttname"><a href="namespacetf.html#ac7a8fe7456b888d6072ba94783c5003c">tf::cuda_free</a></div><div class="ttdeci">void cuda_free(T *ptr, int d)</div><div class="ttdoc">frees memory on the GPU device</div><div class="ttdef"><b>Definition</b> cuda_memory.hpp:101</div></div>
</div><!-- fragment --><p>The reduce algorithm runs <em>asynchronously</em> through the stream specified in the execution policy. You need to synchronize the stream to obtain correct results. Since the GPU reduction algorithm may require extra buffer to store the temporary results, you must provide a buffer of size at least bytes returned from <a class="el" href="namespacetf.html#a1ca0bd68df882048e4b9b4d92efc3168" title="queries the buffer size in bytes needed to call reduce kernels">tf::cuda_reduce_buffer_size</a>.</p>
<dl class="section attention"><dt>Attention</dt><dd>You must keep the buffer alive before the reduction call completes.</dd></dl>
<h1><a class="anchor" id="CUDASTDReduceItemsWithoutAnInitialValue"></a>
Reduce a Range of Items without an Initial Value</h1>
<p><a class="el" href="namespacetf.html#a492e8410db032a0273a99dd905486161" title="performs asynchronous parallel reduction over a range of items without an initial value">tf::cuda_uninitialized_reduce</a> performs a parallel reduction over a range of items without an initial value. This method represents a parallel execution of the following reduction loop on a GPU:</p>
<div class="fragment"><div class="line">*result = *first++;  <span class="comment">// no initial values to participate in the reduction loop</span></div>
<div class="line"><span class="keywordflow">while</span> (first != last) {</div>
<div class="line">  *result = bop(*result, *first++);</div>
<div class="line">}</div>
</div><!-- fragment --><p>The variable <code>result</code> is directly assigned the reduced value without any initial value participating in the reduction loop. The following code performs a parallel reduction to sum all the numbers in the given range without any initial value:</p>
<div class="fragment"><div class="line"><span class="keyword">const</span> <span class="keywordtype">size_t</span> N = 1000000;</div>
<div class="line"><span class="keywordtype">int</span>* res = tf::cuda_malloc_shared&lt;int&gt;(1);  <span class="comment">// result</span></div>
<div class="line"><span class="keywordtype">int</span>* vec = tf::cuda_malloc_shared&lt;int&gt;(N);  <span class="comment">// vector</span></div>
<div class="line"> </div>
<div class="line"><span class="comment">// initializes the data</span></div>
<div class="line"><span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> i=0; i&lt;N; i++) </div>
<div class="line">  vec[i] = i;</div>
<div class="line">} </div>
<div class="line"> </div>
<div class="line"><span class="comment">// queries the required buffer size to reduce N elements using the given policy</span></div>
<div class="line"><a class="code hl_class" href="classtf_1_1cudaExecutionPolicy.html">tf::cudaDefaultExecutionPolicy</a> policy;</div>
<div class="line"><span class="keyword">auto</span> bytes  = tf::cuda_reduce_buffer_size&lt;tf::cudaDefaultExecutionPolicy, int&gt;(N);</div>
<div class="line"><span class="keyword">auto</span> buffer = tf::cuda_malloc_device&lt;std::byte&gt;(bytes);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// *res = 0 + 1 + 2 + 3 + 4 + ... + N-1</span></div>
<div class="line"><a class="code hl_function" href="namespacetf.html#a492e8410db032a0273a99dd905486161">tf::cuda_uninitialized_reduce</a>(policy,</div>
<div class="line">  vec, vec + N, res, [] __device__ (<span class="keywordtype">int</span> a, <span class="keywordtype">int</span> b) { <span class="keywordflow">return</span> a + b; }, buffer</div>
<div class="line">);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// synchronize the execution</span></div>
<div class="line">policy.synchronize();</div>
<div class="line"> </div>
<div class="line"><span class="comment">// delete the buffer</span></div>
<div class="line"><a class="code hl_function" href="namespacetf.html#ac7a8fe7456b888d6072ba94783c5003c">tf::cuda_free</a>(buffer);</div>
<div class="ttc" id="anamespacetf_html_a492e8410db032a0273a99dd905486161"><div class="ttname"><a href="namespacetf.html#a492e8410db032a0273a99dd905486161">tf::cuda_uninitialized_reduce</a></div><div class="ttdeci">void cuda_uninitialized_reduce(P &amp;&amp;p, I first, I last, T *res, O op, void *buf)</div><div class="ttdoc">performs asynchronous parallel reduction over a range of items without an initial value</div><div class="ttdef"><b>Definition</b> reduce.hpp:253</div></div>
</div><!-- fragment --><h1><a class="anchor" id="CUDASTDReduceTransformedItemsWithAnInitialValue"></a>
Reduce a Range of Transformed Items with an Initial Value</h1>
<p><a class="el" href="namespacetf.html#a4463d06240d608bc31d8b3546a851e4e" title="performs asynchronous parallel reduction over a range of transformed items without an initial value">tf::cuda_transform_reduce</a> performs a parallel reduction over a range of <em>transformed</em> elements specified by <code>[first, last)</code> using a binary reduce operator <code>bop</code> and a unary transform operator <code>uop</code>. It represents the parallel execution of the following reduction loop on a GPU:</p>
<div class="fragment"><div class="line"><span class="keywordflow">while</span> (first != last) {</div>
<div class="line">  *result = bop(*result, uop(*first++));</div>
<div class="line">}</div>
</div><!-- fragment --><p>The variable <code>result</code> participates in the reduction loop and must be initialized with an initial value. The following code performs a parallel reduction to sum all the transformed numbers multiplied by <code>10</code> in the given range with an initial value <code>1000</code>:</p>
<div class="fragment"><div class="line"><span class="keyword">const</span> <span class="keywordtype">size_t</span> N = 1000000;</div>
<div class="line"><span class="keywordtype">int</span>* res = tf::cuda_malloc_shared&lt;int&gt;(1);  <span class="comment">// result</span></div>
<div class="line"><span class="keywordtype">int</span>* vec = tf::cuda_malloc_shared&lt;int&gt;(N);  <span class="comment">// vector</span></div>
<div class="line"> </div>
<div class="line"><span class="comment">// initializes the data</span></div>
<div class="line">*res = 1000;</div>
<div class="line"><span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> i=0; i&lt;N; i++) {</div>
<div class="line">  vec[i] = i;</div>
<div class="line">} </div>
<div class="line"> </div>
<div class="line"><span class="comment">// queries the required buffer size to reduce N elements using the given policy</span></div>
<div class="line"><a class="code hl_class" href="classtf_1_1cudaExecutionPolicy.html">tf::cudaDefaultExecutionPolicy</a> policy;</div>
<div class="line"><span class="keyword">auto</span> bytes  = tf::cuda_reduce_buffer_size&lt;tf::cudaDefaultExecutionPolicy, int&gt;(N);</div>
<div class="line"><span class="keyword">auto</span> buffer = tf::cuda_malloc_device&lt;std::byte&gt;(bytes);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// *res = 1000 + (0*10 + 1*10 + 2*10 + 3*10 + 4*10 + ... + (N-1)*10)</span></div>
<div class="line"><a class="code hl_function" href="namespacetf.html#a4463d06240d608bc31d8b3546a851e4e">tf::cuda_transform_reduce</a>(policy,</div>
<div class="line">  vec, vec + N, res, </div>
<div class="line">  [] __device__ (<span class="keywordtype">int</span> a, <span class="keywordtype">int</span> b) { <span class="keywordflow">return</span> a + b; },</div>
<div class="line">  [] __device__ (<span class="keywordtype">int</span> a) { <span class="keywordflow">return</span> a*10; },</div>
<div class="line">  buffer</div>
<div class="line">);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// synchronize the execution</span></div>
<div class="line">policy.synchronize();</div>
<div class="line"> </div>
<div class="line"><span class="comment">// delete the buffer</span></div>
<div class="line"><a class="code hl_function" href="namespacetf.html#ac7a8fe7456b888d6072ba94783c5003c">tf::cuda_free</a>(buffer);</div>
<div class="ttc" id="anamespacetf_html_a4463d06240d608bc31d8b3546a851e4e"><div class="ttname"><a href="namespacetf.html#a4463d06240d608bc31d8b3546a851e4e">tf::cuda_transform_reduce</a></div><div class="ttdeci">void cuda_transform_reduce(P &amp;&amp;p, I first, I last, T *res, O bop, U uop, void *buf)</div><div class="ttdoc">performs asynchronous parallel reduction over a range of transformed items without an initial value</div><div class="ttdef"><b>Definition</b> reduce.hpp:294</div></div>
</div><!-- fragment --><h1><a class="anchor" id="CUDASTDReduceTransformedItemsWithoutAnInitialValue"></a>
Reduce a Range of Transformed Items without an Initial Value</h1>
<p><a class="el" href="namespacetf.html#a747a41c0474fd34da370839b60ddc4ca" title="performs asynchronous parallel reduction over a range of transformed items with an initial value">tf::cuda_transform_uninitialized_reduce</a> performs a parallel reduction over a range of transformed items without an initial value. This method represents a parallel execution of the following reduction loop on a GPU:</p>
<div class="fragment"><div class="line">*result = *first++;  <span class="comment">// no initial values to participate in the reduction loop</span></div>
<div class="line"><span class="keywordflow">while</span> (first != last) {</div>
<div class="line">  *result = bop(*result, uop(*first++));</div>
<div class="line">}</div>
</div><!-- fragment --><p>The variable <code>result</code> is directly assigned the reduced value without any initial value participating in the reduction loop. The following code performs a parallel reduction to sum all the transformed numbers multiplied by <code>10</code> in the given range without any initial value:</p>
<div class="fragment"><div class="line"><span class="keyword">const</span> <span class="keywordtype">size_t</span> N = 1000000;</div>
<div class="line"><span class="keywordtype">int</span>* res = tf::cuda_malloc_shared&lt;int&gt;(1);  <span class="comment">// result</span></div>
<div class="line"><span class="keywordtype">int</span>* vec = tf::cuda_malloc_shared&lt;int&gt;(N);  <span class="comment">// vector</span></div>
<div class="line"> </div>
<div class="line"><span class="comment">// initializes the data</span></div>
<div class="line"><span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> i=0; i&lt;N; i++) {</div>
<div class="line">  vec[i] = i;</div>
<div class="line">} </div>
<div class="line"> </div>
<div class="line"><span class="comment">// queries the required buffer size to reduce N elements using the given policy</span></div>
<div class="line"><a class="code hl_class" href="classtf_1_1cudaExecutionPolicy.html">tf::cudaDefaultExecutionPolicy</a> policy;</div>
<div class="line"><span class="keyword">auto</span> bytes  = tf::cuda_reduce_buffer_size&lt;tf::cudaDefaultExecutionPolicy, int&gt;(N);</div>
<div class="line"><span class="keyword">auto</span> buffer = tf::cuda_malloc_device&lt;std::byte&gt;(bytes);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// *res = 0*10 + 1*10 + 2*10 + 3*10 + 4*10 + ... + (N-1)*10</span></div>
<div class="line"><a class="code hl_function" href="namespacetf.html#a492e8410db032a0273a99dd905486161">tf::cuda_uninitialized_reduce</a>(policy,</div>
<div class="line">  vec, vec + N, res, </div>
<div class="line">  [] __device__ (<span class="keywordtype">int</span> a, <span class="keywordtype">int</span> b) { <span class="keywordflow">return</span> a + b; },</div>
<div class="line">  [] __device__ (<span class="keywordtype">int</span> a) { <span class="keywordflow">return</span> a*10; },</div>
<div class="line">  buffer</div>
<div class="line">);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// synchronize the execution</span></div>
<div class="line">policy.synchronize();</div>
<div class="line"> </div>
<div class="line"><span class="comment">// delete the data</span></div>
<div class="line"><a class="code hl_function" href="namespacetf.html#ac7a8fe7456b888d6072ba94783c5003c">tf::cuda_free</a>(buffer);</div>
<div class="line"><a class="code hl_function" href="namespacetf.html#ac7a8fe7456b888d6072ba94783c5003c">tf::cuda_free</a>(res);</div>
<div class="line"><a class="code hl_function" href="namespacetf.html#ac7a8fe7456b888d6072ba94783c5003c">tf::cuda_free</a>(vec);</div>
</div><!-- fragment --> </div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="cudaStandardAlgorithms.html">CUDA Standard Algorithms</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>

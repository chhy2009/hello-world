<!-- HTML header for doxygen 1.8.13-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Taskflow Handbook</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="icon" type="image/x-icon" href="favicon.ico" />
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="taskflow_logo.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname"><a href="https://taskflow.github.io/">Taskflow</a>
   &#160;<span id="projectnumber">3.2.0-Master-Branch</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('GPUTaskingcudaFlow.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">GPU Tasking (cudaFlow)</div></div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#GPUTaskingcudaFlowIncludeTheHeader">Include the Header</a></li>
<li class="level1"><a href="#Create_a_cudaFlow">Create a cudaFlow</a></li>
<li class="level1"><a href="#Compile_a_cudaFlow_program">Compile a cudaFlow Program</a></li>
<li class="level1"><a href="#run_a_cudaflow_on_a_specific_gpu">Run a cudaFlow on Specific GPU</a></li>
<li class="level1"><a href="#GPUMemoryOperations">Create Memory Operation Tasks</a></li>
<li class="level1"><a href="#StudyThecudaFlowGranularity">Study the Granularity</a></li>
<li class="level1"><a href="#OffloadAcudaFlow">Offload a cudaFlow</a></li>
<li class="level1"><a href="#UpdateAcudaFlow">Update a cudaFlow</a></li>
<li class="level1"><a href="#UsecudaFlowInAStandaloneEnvironment">Use cudaFlow in a Standalone Environment</a></li>
</ul>
</div>
<div class="textblock"><p>Modern scientific computing typically leverages GPU-powered parallel processing cores to speed up large-scale applications. This chapter discusses how to implement CPU-GPU heterogeneous tasking algorithms with <a href="https://developer.nvidia.com/cuda-zone">Nvidia CUDA</a>.</p>
<h1><a class="anchor" id="GPUTaskingcudaFlowIncludeTheHeader"></a>
Include the Header</h1>
<p>You need to include the header file, <code>taskflow/cuda/cudaflow.hpp</code>, for creating a <a class="el" href="classtf_1_1cudaFlow.html" title="class to create a cudaFlow task dependency graph">tf::cudaFlow</a> task.</p>
<h1><a class="anchor" id="Create_a_cudaFlow"></a>
Create a cudaFlow</h1>
<p>Taskflow leverages <a href="https://developer.nvidia.com/blog/cuda-graphs/">CUDA Graph</a> to enable concurrent CPU-GPU tasking using a task graph model, <a class="el" href="classtf_1_1cudaFlow.html" title="class to create a cudaFlow task dependency graph">tf::cudaFlow</a>. A cudaFlow is a task in a taskflow and is associated with a CUDA graph to execute multiple dependent GPU operations in a single CPU call. To create a cudaFlow task, emplace a callable with an argument of type <a class="el" href="classtf_1_1cudaFlow.html" title="class to create a cudaFlow task dependency graph">tf::cudaFlow</a>. The following example implements the canonical saxpy (A·X Plus Y) task graph using <a class="el" href="classtf_1_1cudaFlow.html" title="class to create a cudaFlow task dependency graph">tf::cudaFlow</a>.</p>
<div class="fragment"><div class="line"> 1: #include &lt;taskflow/cuda/cudaflow.hpp&gt;</div>
<div class="line"> 2: </div>
<div class="line"> 3: <span class="comment">// saxpy (single-precision A·X Plus Y) kernel</span></div>
<div class="line"> 4: __global__ <span class="keywordtype">void</span> saxpy(<span class="keywordtype">int</span> n, <span class="keywordtype">float</span> a, <span class="keywordtype">float</span> *x, <span class="keywordtype">float</span> *y) {</div>
<div class="line"> 5:   <span class="keywordtype">int</span> i = blockIdx.x*blockDim.x + threadIdx.x;</div>
<div class="line"> 6:   <span class="keywordflow">if</span> (i &lt; n) {</div>
<div class="line"> 7:     y[i] = a*x[i] + y[i];</div>
<div class="line"> 8:   }</div>
<div class="line"> 9: }</div>
<div class="line">10:</div>
<div class="line">11: <span class="comment">// main function begins</span></div>
<div class="line">12: <span class="keywordtype">int</span> main() {</div>
<div class="line">13:</div>
<div class="line">14:   <a class="code hl_class" href="classtf_1_1Taskflow.html">tf::Taskflow</a> taskflow;</div>
<div class="line">15:   <a class="code hl_class" href="classtf_1_1Executor.html">tf::Executor</a> executor;</div>
<div class="line">16:  </div>
<div class="line">17:   <span class="keyword">const</span> <span class="keywordtype">unsigned</span> N = 1&lt;&lt;20;                            <span class="comment">// size of the vector</span></div>
<div class="line">18:</div>
<div class="line">19:   <a class="code hl_classRef" href="http://en.cppreference.com/w/cpp/container/vector.html">std::vector&lt;float&gt;</a> hx(N, 1.0f);                      <span class="comment">// x vector at host</span></div>
<div class="line">20:   <a class="code hl_classRef" href="http://en.cppreference.com/w/cpp/container/vector.html">std::vector&lt;float&gt;</a> hy(N, 2.0f);                      <span class="comment">// y vector at host</span></div>
<div class="line">21:</div>
<div class="line">22:   <span class="keywordtype">float</span> *dx{<span class="keyword">nullptr</span>};                                  <span class="comment">// x vector at device</span></div>
<div class="line">23:   <span class="keywordtype">float</span> *dy{<span class="keyword">nullptr</span>};                                  <span class="comment">// y vector at device</span></div>
<div class="line">24:  </div>
<div class="line">25:   <a class="code hl_class" href="classtf_1_1Task.html">tf::Task</a> allocate_x = taskflow.<a class="code hl_function" href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">emplace</a>(</div>
<div class="line">26:     [&amp;](){ cudaMalloc(&amp;dx, N*<span class="keyword">sizeof</span>(<span class="keywordtype">float</span>));}</div>
<div class="line">27:   ).name(<span class="stringliteral">&quot;allocate_x&quot;</span>);</div>
<div class="line">28:</div>
<div class="line">29:   <a class="code hl_class" href="classtf_1_1Task.html">tf::Task</a> allocate_y = taskflow.<a class="code hl_function" href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">emplace</a>(</div>
<div class="line">30:     [&amp;](){ cudaMalloc(&amp;dy, N*<span class="keyword">sizeof</span>(<span class="keywordtype">float</span>));}</div>
<div class="line">31:   ).name(<span class="stringliteral">&quot;allocate_y&quot;</span>);</div>
<div class="line">32:</div>
<div class="line">33:   <a class="code hl_class" href="classtf_1_1Task.html">tf::Task</a> cudaflow = taskflow.<a class="code hl_function" href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">emplace</a>([&amp;](<a class="code hl_class" href="classtf_1_1cudaFlow.html">tf::cudaFlow</a>&amp; cf) {</div>
<div class="line">34:     <span class="comment">// create data transfer tasks</span></div>
<div class="line">35:     <a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> h2d_x = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(dx, hx.data(), N).<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;h2d_x&quot;</span>); </div>
<div class="line">36:     <a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> h2d_y = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(dy, hy.data(), N).<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;h2d_y&quot;</span>);</div>
<div class="line">37:     <a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> d2h_x = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(hx.data(), dx, N).<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;d2h_x&quot;</span>);</div>
<div class="line">38:     <a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> d2h_y = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(hy.data(), dy, N).<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;d2h_y&quot;</span>);</div>
<div class="line">39:</div>
<div class="line">40:     <span class="comment">// launch saxpy&lt;&lt;&lt;(N+255)/256, 256, 0&gt;&gt;&gt;(N, 2.0f, dx, dy)</span></div>
<div class="line">41:     <a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> kernel = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#aa6e734462c8b8d922f44e621f94b104c">kernel</a>(</div>
<div class="line">42:       (N+255)/256, 256, 0, saxpy, N, 2.0f, dx, dy</div>
<div class="line">43:     ).name(<span class="stringliteral">&quot;saxpy&quot;</span>);</div>
<div class="line">44:</div>
<div class="line">45:     kernel.<a class="code hl_function" href="classtf_1_1cudaTask.html#a4a9ca1a34bac47e4c9b04eb4fb2f7775">succeed</a>(h2d_x, h2d_y)</div>
<div class="line">46:           .<a class="code hl_function" href="classtf_1_1cudaTask.html#abdd68287ec4dff4216af34d1db44d1b4">precede</a>(d2h_x, d2h_y);</div>
<div class="line">48:   }).name(<span class="stringliteral">&quot;saxpy&quot;</span>);</div>
<div class="line">49:   cudaflow.<a class="code hl_function" href="classtf_1_1Task.html#a331b1b726555072e7c7d10941257f664">succeed</a>(allocate_x, allocate_y);  <span class="comment">// overlap memory alloc</span></div>
<div class="line">50:  </div>
<div class="line">51:   executor.<a class="code hl_function" href="classtf_1_1Executor.html#a519777f5783981d534e9e53b99712069">run</a>(taskflow).wait();</div>
<div class="line">52:</div>
<div class="line">53:   taskflow.<a class="code hl_function" href="classtf_1_1Taskflow.html#ac433018262e44b12c4cc9f0c4748d758">dump</a>(<a class="code hl_classRef" href="http://en.cppreference.com/w/cpp/io/basic_ostream.html">std::cout</a>);                  <span class="comment">// dump the taskflow</span></div>
<div class="line">54: }</div>
<div class="ttc" id="abasic_ostream_html"><div class="ttname"><a href="http://en.cppreference.com/w/cpp/io/basic_ostream.html">std::cout</a></div></div>
<div class="ttc" id="aclasstf_1_1Executor_html"><div class="ttname"><a href="classtf_1_1Executor.html">tf::Executor</a></div><div class="ttdoc">class to create an executor for running a taskflow graph</div><div class="ttdef"><b>Definition</b> executor.hpp:50</div></div>
<div class="ttc" id="aclasstf_1_1Executor_html_a519777f5783981d534e9e53b99712069"><div class="ttname"><a href="classtf_1_1Executor.html#a519777f5783981d534e9e53b99712069">tf::Executor::run</a></div><div class="ttdeci">tf::Future&lt; void &gt; run(Taskflow &amp;taskflow)</div><div class="ttdoc">runs a taskflow once</div><div class="ttdef"><b>Definition</b> executor.hpp:1573</div></div>
<div class="ttc" id="aclasstf_1_1FlowBuilder_html_a60d7a666cab71ecfa3010b2efb0d6b57"><div class="ttname"><a href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">tf::FlowBuilder::emplace</a></div><div class="ttdeci">Task emplace(C &amp;&amp;callable)</div><div class="ttdoc">creates a static task</div><div class="ttdef"><b>Definition</b> flow_builder.hpp:742</div></div>
<div class="ttc" id="aclasstf_1_1Task_html"><div class="ttname"><a href="classtf_1_1Task.html">tf::Task</a></div><div class="ttdoc">class to create a task handle over a node in a taskflow graph</div><div class="ttdef"><b>Definition</b> task.hpp:187</div></div>
<div class="ttc" id="aclasstf_1_1Task_html_a331b1b726555072e7c7d10941257f664"><div class="ttname"><a href="classtf_1_1Task.html#a331b1b726555072e7c7d10941257f664">tf::Task::succeed</a></div><div class="ttdeci">Task &amp; succeed(Ts &amp;&amp;... tasks)</div><div class="ttdoc">adds precedence links from other tasks to this</div><div class="ttdef"><b>Definition</b> task.hpp:428</div></div>
<div class="ttc" id="aclasstf_1_1Taskflow_html"><div class="ttname"><a href="classtf_1_1Taskflow.html">tf::Taskflow</a></div><div class="ttdoc">class to create a taskflow object</div><div class="ttdef"><b>Definition</b> core/taskflow.hpp:73</div></div>
<div class="ttc" id="aclasstf_1_1Taskflow_html_ac433018262e44b12c4cc9f0c4748d758"><div class="ttname"><a href="classtf_1_1Taskflow.html#ac433018262e44b12c4cc9f0c4748d758">tf::Taskflow::dump</a></div><div class="ttdeci">void dump(std::ostream &amp;ostream) const</div><div class="ttdoc">dumps the taskflow to a DOT format through a std::ostream target</div><div class="ttdef"><b>Definition</b> core/taskflow.hpp:363</div></div>
<div class="ttc" id="aclasstf_1_1cudaFlow_html"><div class="ttname"><a href="classtf_1_1cudaFlow.html">tf::cudaFlow</a></div><div class="ttdoc">class to create a cudaFlow task dependency graph</div><div class="ttdef"><b>Definition</b> cudaflow.hpp:56</div></div>
<div class="ttc" id="aclasstf_1_1cudaFlow_html_aa6e734462c8b8d922f44e621f94b104c"><div class="ttname"><a href="classtf_1_1cudaFlow.html#aa6e734462c8b8d922f44e621f94b104c">tf::cudaFlow::kernel</a></div><div class="ttdeci">cudaTask kernel(dim3 g, dim3 b, size_t s, F f, ArgsT &amp;&amp;... args)</div><div class="ttdoc">creates a kernel task</div><div class="ttdef"><b>Definition</b> cudaflow.hpp:1272</div></div>
<div class="ttc" id="aclasstf_1_1cudaFlow_html_af03e04771b655f9e629eb4c22e19b19f"><div class="ttname"><a href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">tf::cudaFlow::copy</a></div><div class="ttdeci">cudaTask copy(T *tgt, const T *src, size_t num)</div><div class="ttdoc">creates a memcopy task that copies typed data</div><div class="ttdef"><b>Definition</b> cudaflow.hpp:1348</div></div>
<div class="ttc" id="aclasstf_1_1cudaTask_html"><div class="ttname"><a href="classtf_1_1cudaTask.html">tf::cudaTask</a></div><div class="ttdoc">class to create a task handle over an internal node of a cudaFlow graph</div><div class="ttdef"><b>Definition</b> cuda_task.hpp:65</div></div>
<div class="ttc" id="aclasstf_1_1cudaTask_html_a4a9ca1a34bac47e4c9b04eb4fb2f7775"><div class="ttname"><a href="classtf_1_1cudaTask.html#a4a9ca1a34bac47e4c9b04eb4fb2f7775">tf::cudaTask::succeed</a></div><div class="ttdeci">cudaTask &amp; succeed(Ts &amp;&amp;... tasks)</div><div class="ttdoc">adds precedence links from other tasks to this</div><div class="ttdef"><b>Definition</b> cuda_task.hpp:189</div></div>
<div class="ttc" id="aclasstf_1_1cudaTask_html_ab81b4f71a44af8d61758524f0c274962"><div class="ttname"><a href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">tf::cudaTask::name</a></div><div class="ttdeci">cudaTask &amp; name(const std::string &amp;name)</div><div class="ttdoc">assigns a name to the task</div><div class="ttdef"><b>Definition</b> cuda_task.hpp:200</div></div>
<div class="ttc" id="aclasstf_1_1cudaTask_html_abdd68287ec4dff4216af34d1db44d1b4"><div class="ttname"><a href="classtf_1_1cudaTask.html#abdd68287ec4dff4216af34d1db44d1b4">tf::cudaTask::precede</a></div><div class="ttdeci">cudaTask &amp; precede(Ts &amp;&amp;... tasks)</div><div class="ttdoc">adds precedence links from this to other tasks</div><div class="ttdef"><b>Definition</b> cuda_task.hpp:182</div></div>
<div class="ttc" id="avector_html"><div class="ttname"><a href="http://en.cppreference.com/w/cpp/container/vector.html">std::vector</a></div></div>
</div><!-- fragment --><div class="dotgraph">
<img src="dot_saxpy.png" alt="dot_saxpy.png" border="0" usemap="#dot_saxpy.map"/>
</div>
<p>Debrief:</p>
<ul>
<li>Lines 3-9 define a saxpy kernel using CUDA </li>
<li>Lines 19-20 declare two host vectors, <code>hx</code> and <code>hy</code> </li>
<li>Lines 22-23 declare two device vector pointers, <code>dx</code> and <code>dy</code> </li>
<li>Lines 25-31 declare two tasks to allocate memory for <code>dx</code> and <code>dy</code> on device, each of <code>N*sizeof(float)</code> bytes </li>
<li>Lines 33-48 create a cudaFlow to define a GPU task graph that contains:<ul>
<li>two host-to-device data transfer tasks</li>
<li>one saxpy kernel task</li>
<li>two device-to-host data transfer tasks </li>
</ul>
</li>
<li>Lines 49-53 define the task dependency between host tasks and the cudaFlow tasks and execute the taskflow</li>
</ul>
<p><a class="el" href="classtf_1_1cudaFlow.html" title="class to create a cudaFlow task dependency graph">tf::cudaFlow</a> is a lightweight abstraction over CUDA Graph. We do not expend yet another effort on simplifying kernel programming but focus on tasking CUDA operations and their dependencies. This organization lets users fully take advantage of CUDA featuress that are commensurate with their domain knowledge, while leaving difficult task parallelism details to Taskflow.</p>
<h1><a class="anchor" id="Compile_a_cudaFlow_program"></a>
Compile a cudaFlow Program</h1>
<p>Use <a href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">nvcc</a> to compile a cudaFlow program:</p>
<div class="fragment"><div class="line">~$ nvcc -std=c++17 my_cudaflow.cu -I path/to/include/taskflow -O2 -o my_cudaflow</div>
<div class="line">~$ ./my_cudaflow</div>
</div><!-- fragment --><p>Please visit the page <a class="el" href="CompileTaskflowWithCUDA.html">Compile Taskflow with CUDA</a> for more details.</p>
<h1><a class="anchor" id="run_a_cudaflow_on_a_specific_gpu"></a>
Run a cudaFlow on Specific GPU</h1>
<p>By default, a cudaFlow runs on the current CUDA GPU associated with the caller, which is typically GPU <code>0</code>. Each CUDA GPU has an integer identifier in the range of <code>[0, N)</code>, where <code>N</code> is the number of CUDA GPUs in a system. You can run a <a class="el" href="classtf_1_1cudaFlow.html" title="class to create a cudaFlow task dependency graph">cudaFlow</a> on a specific GPU using <a class="el" href="classtf_1_1FlowBuilder.html#afdf47fd1a358fb64f8c1b89e2a393169" title="creates a cudaFlow task on the given device">tf::Taskflow::emplace_on</a>. The code below creates a <a class="el" href="classtf_1_1cudaFlow.html" title="class to create a cudaFlow task dependency graph">cudaFlow</a> that runs on GPU <code>2</code>.</p>
<div class="fragment"><div class="line">taskflow.<a class="code hl_function" href="classtf_1_1FlowBuilder.html#afdf47fd1a358fb64f8c1b89e2a393169">emplace_on</a>([] (<a class="code hl_class" href="classtf_1_1cudaFlow.html">tf::cudaFlow</a>&amp; cudaflow) {</div>
<div class="line">  <span class="comment">// here, cudaflow is under GPU 2</span></div>
<div class="line">  <span class="comment">// ...</span></div>
<div class="line">}, 2);  <span class="comment">// place the cudaFlow on GPU 2</span></div>
<div class="ttc" id="aclasstf_1_1FlowBuilder_html_afdf47fd1a358fb64f8c1b89e2a393169"><div class="ttname"><a href="classtf_1_1FlowBuilder.html#afdf47fd1a358fb64f8c1b89e2a393169">tf::FlowBuilder::emplace_on</a></div><div class="ttdeci">Task emplace_on(C &amp;&amp;callable, D &amp;&amp;device)</div><div class="ttdoc">creates a cudaFlow task on the given device</div><div class="ttdef"><b>Definition</b> cudaflow.hpp:1666</div></div>
</div><!-- fragment --><dl class="section attention"><dt>Attention</dt><dd><a class="el" href="classtf_1_1FlowBuilder.html#afdf47fd1a358fb64f8c1b89e2a393169" title="creates a cudaFlow task on the given device">tf::Taskflow::emplace_on</a> allows you to place a cudaFlow on a particular GPU device, but it is your responsibility to ensure correct memory access. For example, you may not allocate a memory block on GPU <code>2</code> while accessing it from a kernel on GPU <code>0</code>.</dd></dl>
<p>An easy practice is to allocate <em>unified shared memory</em> using <code>cudaMallocManaged</code> and let the CUDA runtime perform automatic memory migration between GPUs.</p>
<h1><a class="anchor" id="GPUMemoryOperations"></a>
Create Memory Operation Tasks</h1>
<p><a class="el" href="classtf_1_1cudaFlow.html" title="class to create a cudaFlow task dependency graph">tf::cudaFlow</a> provides a set of methods for users to manipulate device memory. There are two categories, <em>raw</em> data and <em>typed</em> data. Raw data operations are methods with prefix <code>mem</code>, such as <code>memcpy</code> and <code>memset</code>, that operate in <em>bytes</em>. Typed data operations such as <code>copy</code>, <code>fill</code>, and <code>zero</code>, take <em>logical count</em> of elements. For instance, the following three methods have the same result of zeroing <code>sizeof(int)*count</code> bytes of the device memory area pointed to by <code>target</code>.</p>
<div class="fragment"><div class="line"><span class="keywordtype">int</span>* target;</div>
<div class="line">cudaMalloc(&amp;target, count*<span class="keyword">sizeof</span>(<span class="keywordtype">int</span>));</div>
<div class="line">taskflow.<a class="code hl_function" href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">emplace</a>([&amp;](<a class="code hl_class" href="classtf_1_1cudaFlow.html">tf::cudaFlow</a>&amp; cf){</div>
<div class="line">  <a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> memset_target = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#a079ca65da35301e5aafd45878a19e9d2">memset</a>(target, 0, <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>) * count);</div>
<div class="line">  <a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> same_as_above = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#a21d4447bc834f4d3e1bb4772c850d090">fill</a>(target, 0, count);</div>
<div class="line">  <a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> same_as_above_again = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#a40172fac4464f6d805f75921ea3c2a3b">zero</a>(target, count);</div>
<div class="line">});</div>
<div class="ttc" id="aclasstf_1_1cudaFlow_html_a079ca65da35301e5aafd45878a19e9d2"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a079ca65da35301e5aafd45878a19e9d2">tf::cudaFlow::memset</a></div><div class="ttdeci">cudaTask memset(void *dst, int v, size_t count)</div><div class="ttdoc">creates a memset task that fills untyped data with a byte value</div><div class="ttdef"><b>Definition</b> cudaflow.hpp:1367</div></div>
<div class="ttc" id="aclasstf_1_1cudaFlow_html_a21d4447bc834f4d3e1bb4772c850d090"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a21d4447bc834f4d3e1bb4772c850d090">tf::cudaFlow::fill</a></div><div class="ttdeci">cudaTask fill(T *dst, T value, size_t count)</div><div class="ttdoc">creates a memset task that fills a typed memory block with a value</div><div class="ttdef"><b>Definition</b> cudaflow.hpp:1325</div></div>
<div class="ttc" id="aclasstf_1_1cudaFlow_html_a40172fac4464f6d805f75921ea3c2a3b"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a40172fac4464f6d805f75921ea3c2a3b">tf::cudaFlow::zero</a></div><div class="ttdeci">cudaTask zero(T *dst, size_t count)</div><div class="ttdoc">creates a memset task that sets a typed memory block to zero</div><div class="ttdef"><b>Definition</b> cudaflow.hpp:1303</div></div>
</div><!-- fragment --><p>The method <a class="el" href="classtf_1_1cudaFlow.html#a21d4447bc834f4d3e1bb4772c850d090" title="creates a memset task that fills a typed memory block with a value">cudaFlow::fill</a> is a more powerful version of <a class="el" href="classtf_1_1cudaFlow.html#a079ca65da35301e5aafd45878a19e9d2" title="creates a memset task that fills untyped data with a byte value">cudaFlow::memset</a>. It can fill a memory area with any value of type <code>T</code>, given that <code>sizeof(T)</code> is 1, 2, or 4 bytes. For example, the following code sets each element in the array <code>target</code> to 1234.</p>
<div class="fragment"><div class="line">taskflow.<a class="code hl_function" href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">emplace</a>([&amp;](<a class="code hl_class" href="classtf_1_1cudaFlow.html">tf::cudaFlow</a>&amp; cf){ cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#a21d4447bc834f4d3e1bb4772c850d090">fill</a>(target, 1234, count); });</div>
</div><!-- fragment --><p>Similar concept applies to <a class="el" href="classtf_1_1cudaFlow.html#ad37637606f0643f360e9eda1f9a6e559" title="creates a memcpy task that copies untyped data in bytes">cudaFlow::memcpy</a> and <a class="el" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f" title="creates a memcopy task that copies typed data">cudaFlow::copy</a> as well.</p>
<div class="fragment"><div class="line">taskflow.<a class="code hl_function" href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">emplace</a>([&amp;](<a class="code hl_class" href="classtf_1_1cudaFlow.html">tf::cudaFlow</a>&amp; cf){</div>
<div class="line">  <a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> memcpy_target = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#ad37637606f0643f360e9eda1f9a6e559">memcpy</a>(target, source, <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>) * count);</div>
<div class="line">  <a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> same_as_above = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(target, source, count);</div>
<div class="line">});</div>
<div class="ttc" id="aclasstf_1_1cudaFlow_html_ad37637606f0643f360e9eda1f9a6e559"><div class="ttname"><a href="classtf_1_1cudaFlow.html#ad37637606f0643f360e9eda1f9a6e559">tf::cudaFlow::memcpy</a></div><div class="ttdeci">cudaTask memcpy(void *tgt, const void *src, size_t bytes)</div><div class="ttdoc">creates a memcpy task that copies untyped data in bytes</div><div class="ttdef"><b>Definition</b> cudaflow.hpp:1386</div></div>
</div><!-- fragment --><h1><a class="anchor" id="StudyThecudaFlowGranularity"></a>
Study the Granularity</h1>
<p>Creating a cudaFlow has certain overhead, which means <em>fine-grained</em> tasking such as one GPU operation per cudaFlow may not give you any performance gain. You should aggregate as many GPU operations as possible in a cudaFlow to launch the entire graph once instead of separated graphs. For example, the following code creates a fine-grained saxpy task graph using one cudaFlow per GPU operation.</p>
<div class="fragment"><div class="line"><a class="code hl_class" href="classtf_1_1Task.html">tf::Task</a> h2d_x = taskflow.<a class="code hl_function" href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">emplace</a>([&amp;](<a class="code hl_class" href="classtf_1_1cudaFlow.html">tf::cudaFlow</a>&amp; cf) {</div>
<div class="line">  cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(dx, hx.data(), N).<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;h2d_x&quot;</span>);</div>
<div class="line">}).name(<span class="stringliteral">&quot;h2d_x&quot;</span>);  <span class="comment">// creates the 1st cudaFlow</span></div>
<div class="line"> </div>
<div class="line"><a class="code hl_class" href="classtf_1_1Task.html">tf::Task</a> h2d_y = taskflow.<a class="code hl_function" href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">emplace</a>([&amp;](<a class="code hl_class" href="classtf_1_1cudaFlow.html">tf::cudaFlow</a>&amp; cf) {</div>
<div class="line">  cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(dy, hy.data(), N).<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;h2d_y&quot;</span>);</div>
<div class="line">}).name(<span class="stringliteral">&quot;h2d_y&quot;</span>);  <span class="comment">// creates the 2nd cudaFlow </span></div>
<div class="line"> </div>
<div class="line"><a class="code hl_class" href="classtf_1_1Task.html">tf::Task</a> d2h_x = taskflow.<a class="code hl_function" href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">emplace</a>([&amp;](<a class="code hl_class" href="classtf_1_1cudaFlow.html">tf::cudaFlow</a>&amp; cf) {</div>
<div class="line">  cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(hx.data(), dx, N).<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;d2h_x&quot;</span>);</div>
<div class="line">}).name(<span class="stringliteral">&quot;d2h_x&quot;</span>);  <span class="comment">// creates the 3rd cudaFlow</span></div>
<div class="line"> </div>
<div class="line"><a class="code hl_class" href="classtf_1_1Task.html">tf::Task</a> d2h_y = taskflow.<a class="code hl_function" href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">emplace</a>([&amp;](<a class="code hl_class" href="classtf_1_1cudaFlow.html">tf::cudaFlow</a>&amp; cf) {</div>
<div class="line">  cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(hy.data(), dy, N).<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;d2h_y&quot;</span>);</div>
<div class="line">}).name(<span class="stringliteral">&quot;d2h_y&quot;</span>);  <span class="comment">// creates the 4th cudaFlow</span></div>
<div class="line"> </div>
<div class="line"><a class="code hl_class" href="classtf_1_1Task.html">tf::Task</a> kernel = taskflow.<a class="code hl_function" href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">emplace</a>([&amp;](<a class="code hl_class" href="classtf_1_1cudaFlow.html">tf::cudaFlow</a>&amp; cf) {</div>
<div class="line">  cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#aa6e734462c8b8d922f44e621f94b104c">kernel</a>((N+255)/256, 256, 0, saxpy, N, 2.0f, dx, dy).<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;saxpy&quot;</span>);</div>
<div class="line">}).name(<span class="stringliteral">&quot;kernel&quot;</span>); <span class="comment">// creates the 5th cudaFlow</span></div>
<div class="line"> </div>
<div class="line">kernel.<a class="code hl_function" href="classtf_1_1Task.html#a331b1b726555072e7c7d10941257f664">succeed</a>(h2d_x, h2d_y)</div>
<div class="line">      .<a class="code hl_function" href="classtf_1_1Task.html#a8c78c453295a553c1c016e4062da8588">precede</a>(d2h_x, d2h_y);</div>
<div class="ttc" id="aclasstf_1_1Task_html_a8c78c453295a553c1c016e4062da8588"><div class="ttname"><a href="classtf_1_1Task.html#a8c78c453295a553c1c016e4062da8588">tf::Task::precede</a></div><div class="ttdeci">Task &amp; precede(Ts &amp;&amp;... tasks)</div><div class="ttdoc">adds precedence links from this to other tasks</div><div class="ttdef"><b>Definition</b> task.hpp:420</div></div>
</div><!-- fragment --><div class="dotgraph">
<img src="dot_saxpy_5_cudaflow.png" alt="dot_saxpy_5_cudaflow.png" border="0" usemap="#dot_saxpy_5_cudaflow.map"/>
</div>
<p>The following code aggregates the five GPU operations using one cudaFlow to achieve better performance.</p>
<div class="fragment"><div class="line"><a class="code hl_class" href="classtf_1_1Task.html">tf::Task</a> cudaflow = taskflow.<a class="code hl_function" href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">emplace</a>([&amp;](<a class="code hl_class" href="classtf_1_1cudaFlow.html">tf::cudaFlow</a>&amp; cf) {</div>
<div class="line">  <a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> h2d_x = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(dx, hx.data(), N).<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;h2d_x&quot;</span>);</div>
<div class="line">  <a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> h2d_y = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(dy, hy.data(), N).<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;h2d_y&quot;</span>);</div>
<div class="line">  <a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> d2h_x = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(hx.data(), dx, N).<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;d2h_x&quot;</span>);</div>
<div class="line">  <a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> d2h_y = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(hy.data(), dy, N).<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;d2h_y&quot;</span>);</div>
<div class="line">  <a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> saxpy = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#aa6e734462c8b8d922f44e621f94b104c">kernel</a>((N+255)/256, 256, 0, saxpy, N, 2.0f, dx, dy)</div>
<div class="line">                         .<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;saxpy&quot;</span>);</div>
<div class="line">  saxpy.<a class="code hl_function" href="classtf_1_1cudaTask.html#a4a9ca1a34bac47e4c9b04eb4fb2f7775">succeed</a>(h2d_x, h2d_y)</div>
<div class="line">       .<a class="code hl_function" href="classtf_1_1cudaTask.html#abdd68287ec4dff4216af34d1db44d1b4">precede</a>(d2h_x, d2h_y);</div>
<div class="line">}).name(<span class="stringliteral">&quot;saxpy&quot;</span>);  <span class="comment">// creates one cudaFlow</span></div>
</div><!-- fragment --><div class="dotgraph">
<img src="dot_saxpy_1_cudaflow.png" alt="dot_saxpy_1_cudaflow.png" border="0" usemap="#dot_saxpy_1_cudaflow.map"/>
</div>
<dl class="section note"><dt>Note</dt><dd>We encourage users to understand the parallel structure of their applications to come up with the best granularity of task decomposition. A refined task graph can have significant performance difference from the raw counterpart.</dd></dl>
<h1><a class="anchor" id="OffloadAcudaFlow"></a>
Offload a cudaFlow</h1>
<p>By default, the executor offloads and executes the cudaFlow <em>once</em>, if the cudaFlow is never offloaded from its callable. During the execution, the executor first materializes the cudaFlow by mapping it to a native CUDA graph, creates an executable graph from the native CUDA graph, and then submit the executable graph to the CUDA runtime. Similar to <a class="el" href="classtf_1_1Executor.html" title="class to create an executor for running a taskflow graph">tf::Executor</a>, <a class="el" href="classtf_1_1cudaFlow.html" title="class to create a cudaFlow task dependency graph">tf::cudaFlow</a> provides several offload methods to run the GPU task graph:</p>
<div class="fragment"><div class="line">taskflow.<a class="code hl_function" href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">emplace</a>([](<a class="code hl_class" href="classtf_1_1cudaFlow.html">tf::cudaFlow</a>&amp; cf) {</div>
<div class="line">  <span class="comment">// ... create CUDA tasks</span></div>
<div class="line">  cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#a85789ed8a1f47704cf1f1a2b98969444">offload</a>();      <span class="comment">// offload the cudaFlow and run it once</span></div>
<div class="line">  cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#ac2269fd7dc8ca04a294a718204703dad">offload_n</a>(10);  <span class="comment">// offload the cudaFlow and run it 10 times</span></div>
<div class="line">  cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#a99358da15e3bdfa1faabb3e326130e1f">offload_until</a>([repeat=5] () <span class="keyword">mutable</span> { <span class="keywordflow">return</span> repeat-- == 0; })  <span class="comment">// five times</span></div>
<div class="line">});</div>
<div class="ttc" id="aclasstf_1_1cudaFlow_html_a85789ed8a1f47704cf1f1a2b98969444"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a85789ed8a1f47704cf1f1a2b98969444">tf::cudaFlow::offload</a></div><div class="ttdeci">void offload()</div><div class="ttdoc">offloads the cudaFlow and executes it once</div><div class="ttdef"><b>Definition</b> cudaflow.hpp:1654</div></div>
<div class="ttc" id="aclasstf_1_1cudaFlow_html_a99358da15e3bdfa1faabb3e326130e1f"><div class="ttname"><a href="classtf_1_1cudaFlow.html#a99358da15e3bdfa1faabb3e326130e1f">tf::cudaFlow::offload_until</a></div><div class="ttdeci">void offload_until(P &amp;&amp;predicate)</div><div class="ttdoc">offloads the cudaFlow onto a GPU and repeatedly runs it until the predicate becomes true</div><div class="ttdef"><b>Definition</b> cudaflow.hpp:1618</div></div>
<div class="ttc" id="aclasstf_1_1cudaFlow_html_ac2269fd7dc8ca04a294a718204703dad"><div class="ttname"><a href="classtf_1_1cudaFlow.html#ac2269fd7dc8ca04a294a718204703dad">tf::cudaFlow::offload_n</a></div><div class="ttdeci">void offload_n(size_t N)</div><div class="ttdoc">offloads the cudaFlow and executes it by the given times</div><div class="ttdef"><b>Definition</b> cudaflow.hpp:1649</div></div>
</div><!-- fragment --><p>After you offload a cudaFlow, it is considered executed, and the executor will <em>not</em> run an offloaded cudaFlow after leaving the cudaFlow task callable. On the other hand, if a cudaFlow is not offloaded, the executor runs it once. For example, the following two versions represent the same execution logic.</p>
<div class="fragment"><div class="line"><span class="comment">// version 1: explicitly offload a cudaFlow once</span></div>
<div class="line">taskflow.<a class="code hl_function" href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">emplace</a>([](<a class="code hl_class" href="classtf_1_1cudaFlow.html">tf::cudaFlow</a>&amp; cf) {</div>
<div class="line">  cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#ac2906cb0002fc411a983d100a3d58d62">single_task</a>([] __device__ (){});</div>
<div class="line">  cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#a85789ed8a1f47704cf1f1a2b98969444">offload</a>();</div>
<div class="line">});</div>
<div class="line"> </div>
<div class="line"><span class="comment">// version 2 (same as version 1): executor offloads the cudaFlow once</span></div>
<div class="line">taskflow.<a class="code hl_function" href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">emplace</a>([](<a class="code hl_class" href="classtf_1_1cudaFlow.html">tf::cudaFlow</a>&amp; sf) {</div>
<div class="line">  cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#ac2906cb0002fc411a983d100a3d58d62">single_task</a>([] __device__ (){});</div>
<div class="line">});</div>
<div class="ttc" id="aclasstf_1_1cudaFlow_html_ac2906cb0002fc411a983d100a3d58d62"><div class="ttname"><a href="classtf_1_1cudaFlow.html#ac2906cb0002fc411a983d100a3d58d62">tf::cudaFlow::single_task</a></div><div class="ttdeci">cudaTask single_task(C c)</div><div class="ttdoc">runs a callable with only a single kernel thread</div><div class="ttdef"><b>Definition</b> for_each.hpp:169</div></div>
</div><!-- fragment --><h1><a class="anchor" id="UpdateAcudaFlow"></a>
Update a cudaFlow</h1>
<p>Many GPU applications require you to launch a cudaFlow multiple times and update node parameters (e.g., kernel parameters and memory addresses) between iterations. <a class="el" href="classtf_1_1cudaFlow.html#a85789ed8a1f47704cf1f1a2b98969444" title="offloads the cudaFlow and executes it once">tf::cudaFlow::offload</a> allows you to execute the graph immediately and then update the parameters for the next execution. When you offload a cudaFlow, an executable graph will be created, and you must NOT change the topology but the node parameters between successive executions.</p>
<div class="fragment"><div class="line">1: taskflow.<a class="code hl_function" href="classtf_1_1FlowBuilder.html#a60d7a666cab71ecfa3010b2efb0d6b57">emplace</a>([&amp;] (<a class="code hl_class" href="classtf_1_1cudaFlow.html">tf::cudaFlow</a>&amp; cf) {</div>
<div class="line">2:   <a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> task = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#aa6e734462c8b8d922f44e621f94b104c">kernel</a>(grid1, block1, shm1, my_kernel, args1...);</div>
<div class="line">3:   cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#a85789ed8a1f47704cf1f1a2b98969444">offload</a>();  <span class="comment">// immediately run the cudaFlow once</span></div>
<div class="line">4:</div>
<div class="line">5:   cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#aa6e734462c8b8d922f44e621f94b104c">kernel</a>(task, grid2, block2, shm2, my_kernel, args2...);</div>
<div class="line">6:   cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#a85789ed8a1f47704cf1f1a2b98969444">offload</a>();  <span class="comment">// run the cudaFlow again with the same graph topology</span></div>
<div class="line">7:                  <span class="comment">// but with different kernel parameters</span></div>
<div class="line">8: });</div>
</div><!-- fragment --><p>Debrief: </p><ul>
<li>Line 2 creates a kernel task to run <code>my_kernel</code> with the given parameters. </li>
<li>Line 3 offloads the cudaFlow and performs an immediate execution. </li>
<li>Line 5 updates the parameters of <code>my_kernel</code> through its task. </li>
<li>Line 6 executes the cudaFlow again with updated kernel parameters.</li>
</ul>
<p>Between successive offloads (i.e., executions of a cudaFlow), you can update the task parameters, such as changing the kernel execution parameters and memory operation parameters. However, you must <em>NOT</em> change the topology of an offloaded cudaFlow. Each method of task creation in <a class="el" href="classtf_1_1cudaFlow.html" title="class to create a cudaFlow task dependency graph">tf::cudaFlow</a> has an overload that updates the parameters of the task created from the same creation method.</p>
<dl class="section attention"><dt>Attention</dt><dd>There are a few restrictions on updating task parameters in a cudaFlow. Notably, you must <em>NOT</em> change the topology of an offloaded graph. In addition, update methods have the following limitations:<ul>
<li>kernel task<ul>
<li>The kernel function is not allowed to change. This restriction applies to all algorithm tasks that are created using lambda.</li>
</ul>
</li>
<li>memset and memcpy tasks:<ul>
<li>The CUDA device(s) to which the operand(s) was allocated/mapped cannot change</li>
<li>The source/destination memory must be allocated from the same contexts as the original source/destination memory.</li>
</ul>
</li>
</ul>
</dd></dl>
<h1><a class="anchor" id="UsecudaFlowInAStandaloneEnvironment"></a>
Use cudaFlow in a Standalone Environment</h1>
<p>You can use <a class="el" href="classtf_1_1cudaFlow.html" title="class to create a cudaFlow task dependency graph">tf::cudaFlow</a> in a standalone environment without going through <a class="el" href="classtf_1_1Taskflow.html" title="class to create a taskflow object">tf::Taskflow</a> and offloads it to a GPU from the caller thread. All the features we have discussed so far apply to the standalone use. The following code gives an example of using a standalone cudaFlow to create a saxpy task graph that runs on a GPU.</p>
<div class="fragment"><div class="line"><a class="code hl_class" href="classtf_1_1cudaFlow.html">tf::cudaFlow</a> cf;  <span class="comment">// create a standalone cudaFlow</span></div>
<div class="line"> </div>
<div class="line"><a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> h2d_x = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(dx, hx.data(), N).<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;h2d_x&quot;</span>);</div>
<div class="line"><a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> h2d_y = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(dy, hy.data(), N).<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;h2d_y&quot;</span>);</div>
<div class="line"><a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> d2h_x = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(hx.data(), dx, N).<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;d2h_x&quot;</span>);</div>
<div class="line"><a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> d2h_y = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#af03e04771b655f9e629eb4c22e19b19f">copy</a>(hy.data(), dy, N).<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;d2h_y&quot;</span>);</div>
<div class="line"><a class="code hl_class" href="classtf_1_1cudaTask.html">tf::cudaTask</a> saxpy = cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#aa6e734462c8b8d922f44e621f94b104c">kernel</a>((N+255)/256, 256, 0, saxpy, N, 2.0f, dx, dy)</div>
<div class="line">                       .<a class="code hl_function" href="classtf_1_1cudaTask.html#ab81b4f71a44af8d61758524f0c274962">name</a>(<span class="stringliteral">&quot;saxpy&quot;</span>);</div>
<div class="line"> </div>
<div class="line">saxpy.<a class="code hl_function" href="classtf_1_1cudaTask.html#a4a9ca1a34bac47e4c9b04eb4fb2f7775">succeed</a>(h2d_x, h2d_y)   <span class="comment">// kernel runs after  host-to-device copy</span></div>
<div class="line">     .<a class="code hl_function" href="classtf_1_1cudaTask.html#abdd68287ec4dff4216af34d1db44d1b4">precede</a>(d2h_x, d2h_y);  <span class="comment">// kernel runs before device-to-host copy</span></div>
<div class="line"> </div>
<div class="line">cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#a85789ed8a1f47704cf1f1a2b98969444">offload</a>();  <span class="comment">// offload and run the standalone cudaFlow once</span></div>
</div><!-- fragment --><p>When using cudaFlow in a standalone environment, it is your choice to decide its GPU context. The following example creates a cudaFlow and executes it on GPU 0.</p>
<div class="fragment"><div class="line"><a class="code hl_class" href="classtf_1_1cudaScopedDevice.html">tf::cudaScopedDevice</a> gpu(0);</div>
<div class="line"><a class="code hl_class" href="classtf_1_1cudaFlow.html">tf::cudaFlow</a> cf;  <span class="comment">// create a standalone cudaFlow on GPU 0</span></div>
<div class="line">cf.<a class="code hl_function" href="classtf_1_1cudaFlow.html#a85789ed8a1f47704cf1f1a2b98969444">offload</a>();     <span class="comment">// run the capturer once on GPU 0</span></div>
<div class="ttc" id="aclasstf_1_1cudaScopedDevice_html"><div class="ttname"><a href="classtf_1_1cudaScopedDevice.html">tf::cudaScopedDevice</a></div><div class="ttdoc">class to create an RAII-styled context switch</div><div class="ttdef"><b>Definition</b> cuda_device.hpp:293</div></div>
</div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>In the standalone mode, a written cudaFlow will not be executed untile you explicitly call an offload method, as there is neither a taskflow nor an executor. </dd></dl>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="Cookbook.html">Cookbook</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
